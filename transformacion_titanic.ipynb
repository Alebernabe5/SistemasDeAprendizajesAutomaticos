{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a446788",
   "metadata": {},
   "source": [
    "# UD2.2 — Transformación de datos (caso: Titanic)\n",
    "\n",
    "Objetivo: construir un flujo típico de preparación de datos para ML:\n",
    "- Separar columnas numéricas/categóricas\n",
    "- Imputación de nulos\n",
    "- One-Hot / Ordinal encoding\n",
    "- Escalado y su impacto en modelos basados en distancia (KNN)\n",
    "- Pipeline para evitar fugas de datos (data leakage)\n",
    "\n",
    "Regla clave:\n",
    "- `fit` (imputer/encoder/scaler) **solo con train**; después `transform` en test.\n",
    "\n",
    "Dataset: se carga desde `titanic.csv` (local) cuando está disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a0a72",
   "metadata": {},
   "source": [
    "## Paso 0: Importar las librerías necesarias\n",
    "\n",
    "Además de pandas y numpy, importamos las herramientas de **sklearn** para transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d10bdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Herramientas de sklearn para TRANSFORMACIÓN\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler  \u001b[38;5;66;03m# Escalado\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, OneHotEncoder   \u001b[38;5;66;03m# Codificación\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrdinalEncoder                \u001b[38;5;66;03m# Codificación ordinal\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Librerías básicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Herramientas de sklearn para TRANSFORMACIÓN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Escalado\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder   # Codificación\n",
    "from sklearn.preprocessing import OrdinalEncoder                # Codificación ordinal\n",
    "from sklearn.compose import ColumnTransformer                   # Transformar por columnas\n",
    "from sklearn.pipeline import Pipeline                           # Encadenar transformaciones\n",
    "from sklearn.impute import SimpleImputer                        # Rellenar valores faltantes\n",
    "\n",
    "# Para dividir datos y evaluar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librerías importadas correctamente\")\n",
    "\n",
    "print(f\"Versión de Python: {sys.version}\")\n",
    "print(f\"Pandas versión: {pd.__version__}\")\n",
    "print(\"Entorno listo para Aprendizaje Automático.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ca5fc",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y preparar el dataset\n",
    "\n",
    "Cargamos el Titanic y hacemos una limpieza básica antes de transformar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset del Titanic (prioridad: archivo local)\n",
    "from pathlib import Path\n",
    "\n",
    "candidatos = [\n",
    "    Path(\"titanic.csv\"),\n",
    "    Path(\"contenidos/UD2/titanic.csv\"),\n",
    "]\n",
    "\n",
    "df = None\n",
    "origen = None\n",
    "\n",
    "for ruta in candidatos:\n",
    "    if ruta.exists():\n",
    "        df = pd.read_csv(ruta)\n",
    "        origen = str(ruta)\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    origen = url\n",
    "\n",
    "print(f\"Dataset cargado correctamente ({origen})\")\n",
    "print(f\"Tamaño: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73725e2",
   "metadata": {},
   "source": [
    "**Qué deberías ver aquí**\n",
    "- Un `df.head()` con columnas típicas del Titanic (`Survived`, `Pclass`, `Sex`, `Age`, ...).\n",
    "- El tamaño del dataset impreso.\n",
    "- Si la ruta es local, el origen indicará `titanic.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza básica: rellenar valores faltantes\n",
    "# (Lo aprendimos en el capítulo anterior)\n",
    "\n",
    "df_limpio = df.copy()\n",
    "\n",
    "# Rellenar Age con la mediana\n",
    "df_limpio['Age'] = df_limpio['Age'].fillna(df_limpio['Age'].median())\n",
    "\n",
    "# Rellenar Embarked con la moda (valor más frecuente)\n",
    "df_limpio['Embarked'] = df_limpio['Embarked'].fillna(df_limpio['Embarked'].mode()[0])\n",
    "\n",
    "# Eliminar columnas que no usaremos (tienen demasiados valores únicos o faltantes)\n",
    "df_limpio = df_limpio.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
    "\n",
    "print(\"Valores faltantes después de limpieza:\")\n",
    "print(df_limpio.isnull().sum())\n",
    "print(f\"\\nColumnas: {list(df_limpio.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8e942",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EJERCICIO 1: Escalado de Variables Numéricas (Básico)\n",
    "\n",
    "El escalado es crucial para algoritmos que calculan distancias (KNN, SVM) o usan gradiente (Redes Neuronales).\n",
    "\n",
    "Vamos a:\n",
    "1. Identificar las columnas numéricas\n",
    "2. Aplicar StandardScaler (media=0, std=1)\n",
    "3. Aplicar MinMaxScaler (valores entre 0 y 1)\n",
    "4. Comparar los resultados visualmente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71e9c0",
   "metadata": {},
   "source": [
    "## 1.1 Identificar columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41093dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas numéricas y categóricas\n",
    "columnas_numericas = df_limpio.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "columnas_categoricas = df_limpio.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"COLUMNAS NUMÉRICAS:\")\n",
    "print(columnas_numericas)\n",
    "\n",
    "print(\"\\nCOLUMNAS CATEGÓRICAS:\")\n",
    "print(columnas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver las estadísticas de las columnas numéricas ANTES de escalar\n",
    "print(\"ESTADÍSTICAS ANTES DEL ESCALADO:\")\n",
    "print(\"=\"*60)\n",
    "df_limpio[columnas_numericas].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614de03",
   "metadata": {},
   "source": [
    "### Problema: Diferentes escalas\n",
    "\n",
    "Observa:\n",
    "- **Age**: valores entre 0.42 y 80 años\n",
    "- **Fare**: valores entre 0 y 512 libras\n",
    "- **Pclass**: valores 1, 2, 3\n",
    "- **SibSp/Parch**: valores pequeños (0-8)\n",
    "\n",
    "Si usamos KNN sin escalar, el algoritmo pensará que `Fare` es mucho más importante que `Pclass` porque tiene valores más grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b2ee2",
   "metadata": {},
   "source": [
    "## 1.2 Aplicar StandardScaler\n",
    "\n",
    "**StandardScaler** transforma los datos para que tengan:\n",
    "- Media = 0\n",
    "- Desviación estándar = 1\n",
    "\n",
    "Fórmula: $z = \\frac{x - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f54e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo columnas numéricas para escalar\n",
    "# Excluimos 'Survived' porque es la variable objetivo (y)\n",
    "cols_a_escalar = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "\n",
    "# Crear el escalador\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# fit_transform: \n",
    "#   1. fit() calcula la media y desviación de cada columna\n",
    "#   2. transform() aplica la transformación\n",
    "datos_escalados_standard = scaler_standard.fit_transform(df_limpio[cols_a_escalar])\n",
    "\n",
    "# Convertir a DataFrame para ver mejor\n",
    "df_standard = pd.DataFrame(\n",
    "    datos_escalados_standard, \n",
    "    columns=[col + '_scaled' for col in cols_a_escalar]\n",
    ")\n",
    "\n",
    "print(\"DATOS DESPUÉS DE StandardScaler:\")\n",
    "print(\"=\"*60)\n",
    "df_standard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8131c",
   "metadata": {},
   "source": [
    "### Interpretación:\n",
    "- La **media** de cada columna ahora es prácticamente 0\n",
    "- La **desviación estándar** de cada columna es 1\n",
    "- Los valores pueden ser negativos (valores por debajo de la media original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67204e01",
   "metadata": {},
   "source": [
    "## 1.3 Aplicar MinMaxScaler\n",
    "\n",
    "**MinMaxScaler** transforma los datos para que estén entre 0 y 1:\n",
    "\n",
    "Fórmula: $x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ca1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el escalador MinMax\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Aplicar la transformación\n",
    "datos_escalados_minmax = scaler_minmax.fit_transform(df_limpio[cols_a_escalar])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_minmax = pd.DataFrame(\n",
    "    datos_escalados_minmax, \n",
    "    columns=[col + '_minmax' for col in cols_a_escalar]\n",
    ")\n",
    "\n",
    "print(\"DATOS DESPUÉS DE MinMaxScaler:\")\n",
    "print(\"=\"*60)\n",
    "df_minmax.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1f9d5",
   "metadata": {},
   "source": [
    "### Interpretación:\n",
    "- El **mínimo** de cada columna es 0\n",
    "- El **máximo** de cada columna es 1\n",
    "- Todos los valores están en el rango [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3f4ac",
   "metadata": {},
   "source": [
    "## 1.4 Comparación visual: Antes vs Después"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear figura con 3 gráficos: Original, StandardScaler, MinMaxScaler\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Gráfico 1: Datos originales\n",
    "ax1 = axes[0]\n",
    "df_limpio[cols_a_escalar].boxplot(ax=ax1)\n",
    "ax1.set_title('DATOS ORIGINALES\\n(Diferentes escalas)', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Valor')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gráfico 2: StandardScaler\n",
    "ax2 = axes[1]\n",
    "df_standard.boxplot(ax=ax2)\n",
    "ax2.set_title('DESPUÉS DE StandardScaler\\n(Media=0, Std=1)', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('Valor estandarizado')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.axhline(0, color='red', linestyle='--', alpha=0.5, label='Media=0')\n",
    "\n",
    "# Gráfico 3: MinMaxScaler  \n",
    "ax3 = axes[2]\n",
    "df_minmax.boxplot(ax=ax3)\n",
    "ax3.set_title('DESPUÉS DE MinMaxScaler\\n(Valores entre 0 y 1)', fontweight='bold', fontsize=12)\n",
    "ax3.set_ylabel('Valor normalizado')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.axhline(0, color='blue', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(1, color='blue', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.suptitle('Comparación de Métodos de Escalado', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOBSERVACIONES:\")\n",
    "print(\"  - En los datos originales, 'Fare' domina por su escala grande\")\n",
    "print(\"  - Después del escalado, todas las variables tienen escalas comparables\")\n",
    "print(\"  - MinMaxScaler acota los valores entre 0 y 1\")\n",
    "print(\"  - StandardScaler centra en 0 pero puede tener valores fuera de [-1, 1]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d5e76",
   "metadata": {},
   "source": [
    "## 1.5 Demostración: Impacto del escalado en KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c487b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para comparar KNN con y sin escalado\n",
    "\n",
    "# Solo usamos columnas numéricas para este ejemplo\n",
    "X = df_limpio[cols_a_escalar]\n",
    "y = df_limpio['Survived']\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 1. KNN SIN escalar\n",
    "knn_sin_escalar = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sin_escalar.fit(X_train, y_train)\n",
    "acc_sin_escalar = accuracy_score(y_test, knn_sin_escalar.predict(X_test))\n",
    "\n",
    "# 2. KNN CON StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # fit_transform en train\n",
    "X_test_scaled = scaler.transform(X_test)        # solo transform en test (IMPORTANTE!)\n",
    "\n",
    "knn_con_escalar = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_con_escalar.fit(X_train_scaled, y_train)\n",
    "acc_con_escalar = accuracy_score(y_test, knn_con_escalar.predict(X_test_scaled))\n",
    "\n",
    "print(\"COMPARACIÓN DE PRECISIÓN EN KNN:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sin escalar:  {acc_sin_escalar:.2%}\")\n",
    "print(f\"Con escalar:  {acc_con_escalar:.2%}\")\n",
    "print(f\"Mejora:       {(acc_con_escalar - acc_sin_escalar):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97712ee6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EJERCICIO 2: Codificación de Variables Categóricas (Básico-Intermedio)\n",
    "\n",
    "Los algoritmos de ML solo entienden números. Debemos convertir las variables categóricas (Sex, Embarked) a formato numérico.\n",
    "\n",
    "Técnicas:\n",
    "1. **Label Encoding**: Asignar un número a cada categoría (0, 1, 2...)\n",
    "2. **One-Hot Encoding**: Crear una columna binaria por cada categoría\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d5977",
   "metadata": {},
   "source": [
    "## 2.1 Ver las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VARIABLES CATEGÓRICAS EN EL DATASET:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for col in columnas_categoricas:\n",
    "    valores_unicos = df_limpio[col].unique()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Valores únicos: {valores_unicos}\")\n",
    "    print(f\"  Cantidad: {len(valores_unicos)}\")\n",
    "    print(f\"  Frecuencias:\")\n",
    "    print(df_limpio[col].value_counts().to_string().replace('\\n', '\\n    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e468d4d",
   "metadata": {},
   "source": [
    "## 2.2 Label Encoding (para variables binarias)\n",
    "\n",
    "**Label Encoding** es ideal para variables con **2 categorías** (binarias) como `Sex`.\n",
    "\n",
    "- male → 0\n",
    "- female → 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce916d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para no modificar el original\n",
    "df_encoded = df_limpio.copy()\n",
    "\n",
    "# Aplicar Label Encoding a 'Sex'\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['Sex_encoded'] = label_encoder.fit_transform(df_encoded['Sex'])\n",
    "\n",
    "print(\"LABEL ENCODING PARA 'Sex':\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nMapeo realizado:\")\n",
    "for i, clase in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {clase} → {i}\")\n",
    "\n",
    "print(\"\\nPrimeras filas con la nueva columna:\")\n",
    "df_encoded[['Sex', 'Sex_encoded']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeefdd1",
   "metadata": {},
   "source": [
    "## 2.3 One-Hot Encoding (para variables con múltiples categorías)\n",
    "\n",
    "**One-Hot Encoding** crea una columna binaria por cada categoría.\n",
    "\n",
    "Para `Embarked` (C, Q, S):\n",
    "- Embarked_C: 1 si embarcó en Cherbourg, 0 si no\n",
    "- Embarked_Q: 1 si embarcó en Queenstown, 0 si no  \n",
    "- Embarked_S: 1 si embarcó en Southampton, 0 si no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871eeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar One-Hot Encoding a 'Embarked' usando pd.get_dummies()\n",
    "# Esta es la forma más sencilla en pandas\n",
    "\n",
    "embarked_dummies = pd.get_dummies(df_encoded['Embarked'], prefix='Embarked')\n",
    "\n",
    "print(\"ONE-HOT ENCODING PARA 'Embarked':\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNuevas columnas creadas:\")\n",
    "print(embarked_dummies.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir las columnas one-hot al DataFrame\n",
    "df_encoded = pd.concat([df_encoded, embarked_dummies], axis=1)\n",
    "\n",
    "# Verificar resultado\n",
    "print(\"DataFrame con todas las codificaciones:\")\n",
    "df_encoded[['Embarked', 'Embarked_C', 'Embarked_Q', 'Embarked_S']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df7aa72",
   "metadata": {},
   "source": [
    "## 2.4 Visualización de la codificación One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4face6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la matriz One-Hot como un mapa de calor\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico 1: Matriz One-Hot (primeras 20 filas)\n",
    "ax1 = axes[0]\n",
    "sns.heatmap(\n",
    "    df_encoded[['Embarked_C', 'Embarked_Q', 'Embarked_S']].head(20),\n",
    "    cmap='YlGnBu',\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cbar=False,\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set_title('Matriz One-Hot de Embarked\\n(Primeras 20 filas)', fontweight='bold')\n",
    "ax1.set_ylabel('Pasajero')\n",
    "\n",
    "# Gráfico 2: Distribución de puertos de embarque\n",
    "ax2 = axes[1]\n",
    "colores = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "df_encoded['Embarked'].value_counts().plot(kind='bar', ax=ax2, color=colores, edgecolor='black')\n",
    "ax2.set_title('Distribución de Puertos de Embarque', fontweight='bold')\n",
    "ax2.set_xlabel('Puerto')\n",
    "ax2.set_ylabel('Número de pasajeros')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Añadir leyenda\n",
    "puertos = {'C': 'Cherbourg', 'Q': 'Queenstown', 'S': 'Southampton'}\n",
    "for i, (puerto, nombre) in enumerate(puertos.items()):\n",
    "    ax2.text(i, df_encoded['Embarked'].value_counts()[puerto] + 10, \n",
    "             nombre, ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376fd73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EJERCICIO 3: Feature Engineering (Intermedio)\n",
    "\n",
    "**Feature Engineering** es el arte de crear nuevas columnas a partir de las existentes para mejorar el rendimiento del modelo.\n",
    "\n",
    "Vamos a crear:\n",
    "1. `FamilySize`: Tamaño total de la familia\n",
    "2. `IsAlone`: Si el pasajero viaja solo\n",
    "3. `AgeGroup`: Categorización de edad\n",
    "4. `FarePerPerson`: Precio por persona\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para feature engineering\n",
    "df_features = df_limpio.copy()\n",
    "\n",
    "# 1. FamilySize: SibSp (hermanos/esposos) + Parch (padres/hijos) + 1 (el propio pasajero)\n",
    "df_features['FamilySize'] = df_features['SibSp'] + df_features['Parch'] + 1\n",
    "\n",
    "# 2. IsAlone: 1 si FamilySize == 1, 0 si no\n",
    "df_features['IsAlone'] = (df_features['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# 3. AgeGroup: Categorizar la edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 12:\n",
    "        return 'Niño'\n",
    "    elif edad < 18:\n",
    "        return 'Adolescente'\n",
    "    elif edad < 35:\n",
    "        return 'Adulto Joven'\n",
    "    elif edad < 60:\n",
    "        return 'Adulto'\n",
    "    else:\n",
    "        return 'Mayor'\n",
    "\n",
    "df_features['AgeGroup'] = df_features['Age'].apply(categorizar_edad)\n",
    "\n",
    "# 4. FarePerPerson: Precio dividido por tamaño de familia\n",
    "df_features['FarePerPerson'] = df_features['Fare'] / df_features['FamilySize']\n",
    "\n",
    "print(\"NUEVAS FEATURES CREADAS:\")\n",
    "print(\"=\"*60)\n",
    "df_features[['Age', 'AgeGroup', 'SibSp', 'Parch', 'FamilySize', 'IsAlone', 'Fare', 'FarePerPerson']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7745d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las nuevas features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Gráfico 1: Tamaño de familia vs Supervivencia\n",
    "ax1 = axes[0, 0]\n",
    "df_features.groupby('FamilySize')['Survived'].mean().plot(kind='bar', ax=ax1, color='steelblue', edgecolor='black')\n",
    "ax1.set_title('Tasa de Supervivencia por Tamaño de Familia', fontweight='bold')\n",
    "ax1.set_xlabel('Tamaño de Familia')\n",
    "ax1.set_ylabel('Tasa de Supervivencia')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "ax1.axhline(df_features['Survived'].mean(), color='red', linestyle='--', label='Media global')\n",
    "ax1.legend()\n",
    "\n",
    "# Gráfico 2: Solo vs Acompañado\n",
    "ax2 = axes[0, 1]\n",
    "supervivencia_solo = df_features.groupby('IsAlone')['Survived'].mean()\n",
    "bars = ax2.bar(['Acompañado', 'Solo'], supervivencia_solo.values, color=['#27ae60', '#e74c3c'], edgecolor='black')\n",
    "ax2.set_title('Tasa de Supervivencia: Solo vs Acompañado', fontweight='bold')\n",
    "ax2.set_ylabel('Tasa de Supervivencia')\n",
    "for bar, val in zip(bars, supervivencia_solo.values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.1%}', ha='center', fontsize=12)\n",
    "\n",
    "# Gráfico 3: Grupo de edad vs Supervivencia\n",
    "ax3 = axes[1, 0]\n",
    "orden_edad = ['Niño', 'Adolescente', 'Adulto Joven', 'Adulto', 'Mayor']\n",
    "supervivencia_edad = df_features.groupby('AgeGroup')['Survived'].mean().reindex(orden_edad)\n",
    "supervivencia_edad.plot(kind='bar', ax=ax3, color='coral', edgecolor='black')\n",
    "ax3.set_title('Tasa de Supervivencia por Grupo de Edad', fontweight='bold')\n",
    "ax3.set_xlabel('Grupo de Edad')\n",
    "ax3.set_ylabel('Tasa de Supervivencia')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gráfico 4: Distribución de FarePerPerson\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(df_features['FarePerPerson'], bins=30, color='purple', edgecolor='white', alpha=0.7)\n",
    "ax4.set_title('Distribución de Precio por Persona', fontweight='bold')\n",
    "ax4.set_xlabel('Precio por Persona (£)')\n",
    "ax4.set_ylabel('Frecuencia')\n",
    "ax4.axvline(df_features['FarePerPerson'].median(), color='red', linestyle='--', label=f\"Mediana: £{df_features['FarePerPerson'].median():.2f}\")\n",
    "ax4.legend()\n",
    "\n",
    "plt.suptitle('Análisis de Features Creadas', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c60423",
   "metadata": {},
   "source": [
    "### Conclusiones del Feature Engineering:\n",
    "\n",
    "- Los **niños** tuvieron mayor tasa de supervivencia (\"mujeres y niños primero\")\n",
    "- Viajar **acompañado** aumentaba las probabilidades de sobrevivir\n",
    "- Familias de **2-4 personas** tuvieron mejor supervivencia que los que iban solos o en grupos muy grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e263b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EJERCICIO 4: Pipeline Completo (Avanzado)\n",
    "\n",
    "Un **Pipeline** encadena todas las transformaciones en un solo objeto. Ventajas:\n",
    "1. **Reproducibilidad**: Siempre se aplican los mismos pasos\n",
    "2. **Prevención de Data Leakage**: El escalador se ajusta solo con datos de train\n",
    "3. **Código limpio**: Todo en un solo objeto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para el pipeline\n",
    "df_pipeline = df_limpio.copy()\n",
    "\n",
    "# Definir columnas por tipo\n",
    "columnas_numericas_pipeline = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "columnas_categoricas_pipeline = ['Sex', 'Embarked']\n",
    "\n",
    "# Separar features (X) y target (y)\n",
    "X = df_pipeline[columnas_numericas_pipeline + columnas_categoricas_pipeline]\n",
    "y = df_pipeline['Survived']\n",
    "\n",
    "print(\"DATOS PARA EL PIPELINE:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nColumnas numéricas: {columnas_numericas_pipeline}\")\n",
    "print(f\"Columnas categóricas: {columnas_categoricas_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear transformadores para cada tipo de columna\n",
    "\n",
    "# Pipeline para columnas NUMÉRICAS:\n",
    "# 1. Imputar valores faltantes con la mediana\n",
    "# 2. Escalar con StandardScaler\n",
    "transformador_numerico = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para columnas CATEGÓRICAS:\n",
    "# 1. Imputar valores faltantes con 'Desconocido'\n",
    "# 2. Aplicar One-Hot Encoding\n",
    "transformador_categorico = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Desconocido')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "print(\"Transformadores creados:\")\n",
    "print(\"  - transformador_numerico: Imputer + StandardScaler\")\n",
    "print(\"  - transformador_categorico: Imputer + OneHotEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar transformadores con ColumnTransformer\n",
    "# Esto aplica cada transformador a sus columnas correspondientes\n",
    "\n",
    "preprocesador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', transformador_numerico, columnas_numericas_pipeline),\n",
    "        ('cat', transformador_categorico, columnas_categoricas_pipeline)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crear pipeline completo: preprocesador + modelo\n",
    "pipeline_completo = Pipeline(steps=[\n",
    "    ('preprocesador', preprocesador),\n",
    "    ('clasificador', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "print(\"ESTRUCTURA DEL PIPELINE:\")\n",
    "print(\"=\"*50)\n",
    "print(pipeline_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el pipeline completo\n",
    "# fit() automáticamente:\n",
    "#   1. Ajusta el imputador y escalador SOLO con datos de train\n",
    "#   2. Entrena el modelo con los datos transformados\n",
    "pipeline_completo.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "# predict() automáticamente:\n",
    "#   1. Transforma X_test usando los parámetros aprendidos de train\n",
    "#   2. Hace la predicción\n",
    "y_pred = pipeline_completo.predict(X_test)\n",
    "\n",
    "# Evaluar\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"RESULTADOS DEL PIPELINE:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precisión en test: {precision:.2%}\")\n",
    "print(f\"\\nEl pipeline transformó y predijo automáticamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6939089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver cómo quedaron los datos después del preprocesamiento\n",
    "X_train_transformado = preprocesador.fit_transform(X_train)\n",
    "\n",
    "# Obtener nombres de las columnas generadas\n",
    "nombres_columnas = (\n",
    "    columnas_numericas_pipeline + \n",
    "    list(preprocesador.named_transformers_['cat']\n",
    "         .named_steps['onehot']\n",
    "         .get_feature_names_out(columnas_categoricas_pipeline))\n",
    ")\n",
    "\n",
    "df_transformado = pd.DataFrame(X_train_transformado, columns=nombres_columnas)\n",
    "\n",
    "print(\"DATOS DESPUÉS DEL PREPROCESAMIENTO:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDimensiones: {df_transformado.shape}\")\n",
    "print(f\"\\nColumnas generadas: {list(df_transformado.columns)}\")\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "df_transformado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc6c97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Resumen del Ejercicio\n",
    "\n",
    "En este cuaderno hemos aprendido a:\n",
    "\n",
    "| Técnica | Herramienta | Uso |\n",
    "|---------|-------------|-----|\n",
    "| **Escalado Standard** | `StandardScaler` | Media=0, Std=1. Para algoritmos con gradiente |\n",
    "| **Escalado MinMax** | `MinMaxScaler` | Valores entre 0 y 1. Para redes neuronales |\n",
    "| **Label Encoding** | `LabelEncoder` | Variables binarias (Sí/No, Male/Female) |\n",
    "| **One-Hot Encoding** | `pd.get_dummies()` o `OneHotEncoder` | Variables con múltiples categorías |\n",
    "| **Feature Engineering** | Código manual | Crear nuevas columnas informativas |\n",
    "| **Pipeline** | `Pipeline` + `ColumnTransformer` | Automatizar todo el proceso |\n",
    "\n",
    "---\n",
    "\n",
    "**¡Felicidades!** Has completado el ejercicio práctico de Transformación de Datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
